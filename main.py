import os
import time
import functools
import uuid
import logging

import streamlit as st
import streamlit.components.v1 as components
from dotenv import load_dotenv

import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_community.document_transformers import LongContextReorder
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import ChatOpenAI

# ë¡œê·¸ ë ˆë²¨ ê°ì†Œ
logging.basicConfig(level=logging.WARNING)

load_dotenv()

# â€”â€”â€” ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼ â€”â€”â€”
def load_custom_css():
    st.markdown("""
    <style>
    /* ì „ì²´ ë°°ê²½ */
    .stApp {
        background: linear-gradient(135deg, #f5f3ff 0%, #faf9ff 50%, #fffbeb 100%);
    }
    
    /* ë©”ì¸ ì»¨í…Œì´ë„ˆ */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        max-width: 1200px;
    }
    
    /* í—¤ë” ìŠ¤íƒ€ì¼ */
    .header-container {
        background: linear-gradient(135deg, #8b5cf6 0%, #a78bfa 50%, #c4b5fd 100%);
        padding: 2.5rem 2rem;
        border-radius: 20px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(139, 92, 246, 0.3);
        text-align: center;
        position: relative;
        overflow: hidden;
    }
    
    .header-container::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: linear-gradient(45deg, transparent 30%, rgba(255,255,255,0.1) 50%, transparent 70%);
        animation: shimmer 3s infinite;
    }
    
    @keyframes shimmer {
        0% { transform: translateX(-100%) translateY(-100%) rotate(45deg); }
        100% { transform: translateX(100%) translateY(100%) rotate(45deg); }
    }
    
    .header-title {
        color: white;
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        position: relative;
        z-index: 1;
    }
    
    .header-subtitle {
        color: #fef3c7;
        font-size: 1.2rem;
        font-weight: 400;
        position: relative;
        z-index: 1;
    }
    
    .highlight {
        color: #fbbf24;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    /* ì±„íŒ… ì»¨í…Œì´ë„ˆ */
    .chat-container {
        background: transparent;  /* ë°°ê²½ì„ íˆ¬ëª…í•˜ê²Œ */
        /* ë‚˜ë¨¸ì§€ ìŠ¤íƒ€ì¼ë“¤ì€ ì œê±° */
        padding: 1.5rem;
        margin: 1rem 0;
    }
    
    /* ì‚¬ìš©ì ë©”ì‹œì§€ */
    .user-message {
        display: flex;
        justify-content: flex-end;
        margin: 1rem 0;
        animation: slideInRight 0.3s ease-out;
    }
    
    .user-bubble {
        max-width: 75%;
        background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
        padding: 1rem 1.5rem;
        border-radius: 20px 20px 8px 20px;
        border: 2px solid #f59e0b;
        box-shadow: 0 4px 15px rgba(245, 158, 11, 0.2);
        position: relative;
    }
    
    .user-bubble::before {
        content: 'ğŸ‘¤';
        position: absolute;
        right: -0.5rem;
        top: -0.5rem;
        background: #f59e0b;
        border-radius: 50%;
        width: 2rem;
        height: 2rem;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1rem;
    }
    
    /* AI ë©”ì‹œì§€ */
    .ai-message {
        display: flex;
        justify-content: flex-start;
        margin: 1rem 0;
        animation: slideInLeft 0.3s ease-out;
    }
    
    .ai-bubble {
        max-width: 75%;
        background: linear-gradient(135deg, #e0e7ff 0%, #c7d2fe 100%);
        padding: 1rem 1.5rem;
        border-radius: 20px 20px 20px 8px;
        border: 2px solid #8b5cf6;
        box-shadow: 0 4px 15px rgba(139, 92, 246, 0.2);
        position: relative;
    }
    
    .ai-bubble::before {
        content: 'ğŸ¤–';
        position: absolute;
        left: -0.5rem;
        top: -0.5rem;
        background: #8b5cf6;
        border-radius: 50%;
        width: 2rem;
        height: 2rem;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1rem;
    }
    
    @keyframes slideInRight {
        from { transform: translateX(50px); opacity: 0; }
        to { transform: translateX(0); opacity: 1; }
    }
    
    @keyframes slideInLeft {
        from { transform: translateX(-50px); opacity: 0; }
        to { transform: translateX(0); opacity: 1; }
    }
    
    /* ê´‘ê³  ë°°ë„ˆ */
    .ad-banner {
        background: linear-gradient(135deg, #fffbeb 0%, #fef3c7 100%);
        border: 2px solid #f59e0b;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1.5rem 0;
        box-shadow: 0 6px 20px rgba(245, 158, 11, 0.15);
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    
    .ad-banner:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(245, 158, 11, 0.25);
    }
    
    .ad-item {
        display: flex;
        align-items: center;
        padding: 1rem;
        margin: 0.5rem 0;
        background: rgba(255, 255, 255, 0.7);
        border-radius: 12px;
        transition: background 0.3s ease;
    }
    
    .ad-item:hover {
        background: rgba(255, 255, 255, 0.9);
    }
    
    .ad-icon {
        margin-right: 1rem;
        display: flex;
        align-items: center;
        justify-content: center;
        width: 80px;
        height: 60px;
        border-radius: 10px;
        color: white;
        font-size: 24px;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1);
    }
    
    /* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ */
    .css-1d391kg {
        background: linear-gradient(180deg, #f8fafc 0%, #f1f5f9 100%);
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(135deg, #8b5cf6 0%, #a78bfa 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(139, 92, 246, 0.3);
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #7c3aed 0%, #8b5cf6 100%);
        transform: translateY(-2px);
        box-shadow: 0 6px 20px rgba(139, 92, 246, 0.4);
    }
    
    /* ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ */
    .stTextInput > div > div > input {
        border-radius: 15px;
        border: 2px solid #c4b5fd;
        padding: 0.75rem 1rem;
        font-size: 1rem;
        transition: border-color 0.3s ease, box-shadow 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #8b5cf6;
        box-shadow: 0 0 0 3px rgba(139, 92, 246, 0.1);
    }
    
    /* ì‚¬ì´ë“œë°” ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    .sidebar-card {
        background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
        border: 1px solid #e2e8f0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
    }
    
    /* ìŠ¤í”¼ë„ˆ ìŠ¤íƒ€ì¼ */
    .stSpinner > div {
        border-top-color: #8b5cf6 !important;
    }
    
    /* ì œëª© ìŠ¤íƒ€ì¼ ê°œì„  */
    h1, h2, h3 {
        color: #6b21a8;
        font-weight: 700;
    }
    
    /* ì •ë³´ ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .stInfo {
        background: linear-gradient(135deg, #e0e7ff 0%, #c7d2fe 100%);
        border: 1px solid #8b5cf6;
        border-radius: 12px;
    }
    
    .stWarning {
        background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
        border: 1px solid #f59e0b;
        border-radius: 12px;
    }
    
    /* êµ¬ë¶„ì„  ìŠ¤íƒ€ì¼ */
    hr {
        border: none;
        height: 2px;
        background: linear-gradient(90deg, transparent 0%, #c4b5fd 50%, transparent 100%);
        margin: 2rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
# ìµœì í™”ëœ ì¡°ê±´ë¶€ ë²•ë¥ -ë‰´ìŠ¤ RAG ì‹œìŠ¤í…œ (ì¼ìƒì–´â†’ë²•ë¥ ì–´ ì „ì²˜ë¦¬ ì¶”ê°€)
import os
import numpy as np
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_community.document_transformers import LongContextReorder
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import chromadb
from chromadb.utils import embedding_functions
import logging
from functools import lru_cache
import time

# ë©”ëª¨ë¦¬ ê´€ë ¨ import
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_openai import ChatOpenAI

# ë¡œê¹… ì„¤ì • ìµœì í™”
logging.basicConfig(level=logging.WARNING)

# 1. ì¼ìƒì–´ â†’ ë²•ë¥ ì–´ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ ì¶”ê°€
class LegalQueryPreprocessor:
    """ì¼ìƒì–´ë¥¼ ë²•ë¥  ìš©ì–´ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.1,  # ì¼ê´€ëœ ë³€í™˜ì„ ìœ„í•´ ë‚®ê²Œ ì„¤ì •
            max_tokens=200,
        )
        
        # ìºì‹œë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ (ì„¸ì…˜ ë™ì•ˆ ìœ ì§€)
        self._query_cache = {}
        
        # ê¸°ë³¸ ìš©ì–´ ë§¤í•‘ (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë£°ë² ì´ìŠ¤)
        self.term_mapping = {
            # ë¶€ë™ì‚° ê´€ë ¨
            "ì§‘ì£¼ì¸": "ì„ëŒ€ì¸",
            "ì„¸ì…ì": "ì„ì°¨ì¸", 
            "ì „ì„¸ê¸ˆ": "ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ",
            "ë³´ì¦ê¸ˆ": "ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ",
            "ì›”ì„¸": "ì°¨ì„",
            "ë°©ì„¸": "ì°¨ì„",
            "ê³„ì•½ì„œ": "ì„ëŒ€ì°¨ê³„ì•½ì„œ",
            "ì§‘ ë‚˜ê°€ë¼": "ëª…ë„ì²­êµ¬",
            "ì«“ê²¨ë‚˜ë‹¤": "ëª…ë„",
            "ëˆ ì•ˆì¤˜": "ì±„ë¬´ë¶ˆì´í–‰",
            "ëˆ ëª»ë°›ì•„": "ë³´ì¦ê¸ˆë°˜í™˜ì²­êµ¬",
            "ì‚¬ê¸°": "ì‚¬ê¸°ì£„",
            "ì†ì•˜ë‹¤": "ê¸°ë§í–‰ìœ„",
            "ê¹¡í†µì „ì„¸": "ì „ì„¸ì‚¬ê¸°",
            "ì´ì¤‘ê³„ì•½": "ì¤‘ë³µì„ëŒ€",
            
            # ë²•ì  ì ˆì°¨ ê´€ë ¨
            "ê³ ì†Œ": "í˜•ì‚¬ê³ ë°œ",
            "ê³ ë°œ": "í˜•ì‚¬ê³ ë°œ", 
            "ì†Œì†¡": "ë¯¼ì‚¬ì†Œì†¡",
            "ì¬íŒ": "ì†Œì†¡",
            "ë³€í˜¸ì‚¬": "ë²•ë¬´ì‚¬",
            "ìƒë‹´": "ë²•ë¥ ìƒë‹´",
            "í•´ê²°": "ë¶„ìŸí•´ê²°",
            "ë³´ìƒ": "ì†í•´ë°°ìƒ",
            "ë°°ìƒ": "ì†í•´ë°°ìƒ",
            
            # ê¸°íƒ€
            "ê³„ì•½": "ë²•ë¥ í–‰ìœ„",
            "ì•½ì†": "ê³„ì•½",
            "ìœ„ë°˜": "ì±„ë¬´ë¶ˆì´í–‰",
            "ì–´ê¸°ë‹¤": "ìœ„ë°˜í•˜ë‹¤"
        }
    
    def _apply_rule_based_conversion(self, query: str) -> str:
        """ë£°ë² ì´ìŠ¤ ìš©ì–´ ë³€í™˜ (ë¹ ë¥¸ ì²˜ë¦¬)"""
        converted_query = query
        for common_term, legal_term in self.term_mapping.items():
            if common_term in converted_query:
                converted_query = converted_query.replace(common_term, legal_term)
        return converted_query
    
    def _is_already_legal_query(self, query: str) -> bool:
        """ì´ë¯¸ ë²•ë¥  ìš©ì–´ê°€ í¬í•¨ëœ ì¿¼ë¦¬ì¸ì§€ í™•ì¸"""
        legal_indicators = [
            "ì„ëŒ€ì¸", "ì„ì°¨ì¸", "ì„ëŒ€ì°¨", "ëª…ë„", "ì±„ë¬´ë¶ˆì´í–‰", 
            "ì†í•´ë°°ìƒ", "ë¯¼ì‚¬ì†Œì†¡", "í˜•ì‚¬ê³ ë°œ", "ë³´ì¦ê¸ˆë°˜í™˜",
            "ë²•ë¥ ", "íŒë¡€", "ë²•ë ¹", "ì†Œì†¡", "ê³„ì•½ì„œ"
        ]
        return any(term in query for term in legal_indicators)
    
    @lru_cache(maxsize=100)
    def _gpt_convert_to_legal_terms(self, user_query: str) -> str:
        """GPTë¥¼ ì‚¬ìš©í•œ ì •êµí•œ ë²•ë¥  ìš©ì–´ ë³€í™˜ (ìºì‹± ì ìš©)"""
        try:
            prompt = f"""ë‹¤ìŒ ì¼ìƒì–´ ì§ˆë¬¸ì„ ë²•ë¥  ê²€ìƒ‰ì— ì í•©í•œ ì „ë¬¸ ìš©ì–´ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
            
            ì›ë˜ ì§ˆë¬¸: {user_query}

            ë³€í™˜ ê·œì¹™:
            1. ì¼ìƒì–´ë¥¼ ì •í™•í•œ ë²•ë¥  ìš©ì–´ë¡œ ë°”ê¾¸ê¸°
            - ì§‘ì£¼ì¸ â†’ ì„ëŒ€ì¸
            - ì„¸ì…ì â†’ ì„ì°¨ì¸  
            - ì „ì„¸ê¸ˆ/ë³´ì¦ê¸ˆ â†’ ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ
            - ì›”ì„¸ â†’ ì°¨ì„
            - ê³„ì•½ì„œ â†’ ì„ëŒ€ì°¨ê³„ì•½ì„œ
            - ì‚¬ê¸° â†’ ì „ì„¸ì‚¬ê¸° ë˜ëŠ” ì‚¬ê¸°ì£„
            - ì«“ê²¨ë‚˜ë‹¤ â†’ ëª…ë„ì²­êµ¬

            2. í•µì‹¬ ë²•ì  ìŸì ì„ ë¶€ê°ì‹œí‚¤ê¸°
            3. ê²€ìƒ‰ì— ë„ì›€ì´ ë˜ëŠ” ê´€ë ¨ ë²•ë¥  í‚¤ì›Œë“œ ì¶”ê°€
            4. ì›ë˜ ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë©´ì„œ ë” ì •í™•í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ í‘œí˜„

            ë³€í™˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬:"""

            messages = [{"role": "user", "content": prompt}]
            response = self.llm.invoke(messages)
            
            # ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
            converted = response.content.strip()
            if "ë³€í™˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬:" in converted:
                converted = converted.split("ë³€í™˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬:")[-1].strip()
            
            return converted
            
        except Exception as e:
            print(f"âš ï¸ GPT ë³€í™˜ ì‹¤íŒ¨, ë£°ë² ì´ìŠ¤ ë³€í™˜ ì‚¬ìš©: {e}")
            return self._apply_rule_based_conversion(user_query)
    
    def convert_query(self, user_query: str) -> tuple[str, str]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë²•ë¥  ê²€ìƒ‰ì— ì í•©í•˜ê²Œ ë³€í™˜
        
        Returns:
            tuple: (ë³€í™˜ëœ_ì¿¼ë¦¬, ë³€í™˜_ë°©ë²•)
        """
        try:
            # 1. ì´ë¯¸ ë²•ë¥  ìš©ì–´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if self._is_already_legal_query(user_query):
                return user_query, "no_conversion"
            
            # 2. ìºì‹œ í™•ì¸
            if user_query in self._query_cache:
                return self._query_cache[user_query], "cached"
            
            # 3. ë¨¼ì € ë£°ë² ì´ìŠ¤ ë³€í™˜ ì‹œë„
            rule_converted = self._apply_rule_based_conversion(user_query)
            
            # 4. ë£°ë² ì´ìŠ¤ ë³€í™˜ìœ¼ë¡œ ì¶©ë¶„í•œ ê²½ìš° (ë§ì€ ë³€í™˜ì´ ì¼ì–´ë‚œ ê²½ìš°)
            if len(rule_converted) != len(user_query) or rule_converted != user_query:
                # ë£°ë² ì´ìŠ¤ ë³€í™˜ì´ íš¨ê³¼ê°€ ìˆì—ˆë‹¤ë©´ ê²°ê³¼ ìºì‹±
                self._query_cache[user_query] = rule_converted
                return rule_converted, "rule_based"
            
            # 5. ë³µì¡í•œ ê²½ìš° GPT ë³€í™˜ (ì‹œê°„ì´ ë” ê±¸ë¦¬ì§€ë§Œ ì •í™•í•¨)
            print("ğŸ”„ ì •êµí•œ ë²•ë¥  ìš©ì–´ ë³€í™˜ ì¤‘...")
            gpt_converted = self._gpt_convert_to_legal_terms(user_query)
            
            # ê²°ê³¼ ìºì‹±
            self._query_cache[user_query] = gpt_converted
            return gpt_converted, "gpt_converted"
            
        except Exception as e:
            print(f"âš ï¸ ì¿¼ë¦¬ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return user_query, "error"

# 2. ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì„ë² ë”© ëª¨ë¸ ìµœì í™” (ê¸°ì¡´ê³¼ ë™ì¼)
class SingletonMeta(type):
    _instances = {}
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super().__call__(*args, **kwargs)
        return cls._instances[cls]

class OptimizedKoSBERTEmbeddings(metaclass=SingletonMeta):
    def __init__(self, model_name="jhgan/ko-sbert-sts"):
        if not hasattr(self, 'model'):
            print(f"ğŸ”„ KoSBERT ëª¨ë¸ ë¡œë”©: {model_name}")
            self.model = SentenceTransformer(model_name)
            print("âœ… KoSBERT ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    
    @lru_cache(maxsize=128)
    def embed_query_cached(self, text):
        return tuple(self.model.encode(text))
    
    def embed_documents(self, texts):
        return self.model.encode(texts, batch_size=32)
    
    def embed_query(self, text):
        cached_result = self.embed_query_cached(text)
        return np.array(cached_result)

class OptimizedChromaDefaultEmbeddings(metaclass=SingletonMeta):
    def __init__(self):
        if not hasattr(self, 'embedding_function'):
            from chromadb.utils import embedding_functions
            self.embedding_function = embedding_functions.DefaultEmbeddingFunction()
    
    @lru_cache(maxsize=128)
    def embed_query_cached(self, text):
        result = self.embedding_function([text])
        return tuple(result[0])
    
    def embed_documents(self, texts):
        try:
            return self.embedding_function(texts)
        except Exception as e:
            print(f"âš ï¸ ë°°ì¹˜ ì„ë² ë”© ì‹¤íŒ¨, ê°œë³„ ì²˜ë¦¬: {e}")
            results = []
            for text in texts:
                try:
                    result = self.embedding_function([text])
                    results.append(result[0])
                except Exception as ex:
                    print(f"âš ï¸ ê°œë³„ í…ìŠ¤íŠ¸ ì„ë² ë”© ì‹¤íŒ¨: {ex}")
                    results.append([0.0] * 384)
            return results
    
    def embed_query(self, text):
        try:
            cached_result = self.embed_query_cached(text)
            return np.array(cached_result)
        except Exception as e:
            print(f"âš ï¸ ì¿¼ë¦¬ ì„ë² ë”© ìºì‹œ ì‹¤íŒ¨: {e}")
            result = self.embedding_function([text])
            return np.array(result[0])

# 3. ì „ì²˜ë¦¬ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ìµœì í™”ëœ ì¡°ê±´ë¶€ ê²€ìƒ‰ ì‹œìŠ¤í…œ
class OptimizedConditionalRAGSystem:
    def __init__(self, legal_db_path, news_db_path, legal_collection, news_collection):
        print("ğŸš€ ìµœì í™”ëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        start_time = time.time()
        
        # ì¿¼ë¦¬ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        print("ğŸ”„ ë²•ë¥  ìš©ì–´ ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì¤‘...")
        self.query_preprocessor = LegalQueryPreprocessor()
        print("âœ… ë²•ë¥  ìš©ì–´ ì „ì²˜ë¦¬ê¸° ì¤€ë¹„ ì™„ë£Œ")
        
        # ì„ë² ë”© í•¨ìˆ˜ ì´ˆê¸°í™”
        self.legal_embedding_function = OptimizedKoSBERTEmbeddings()
        print("ğŸ“Š ë²•ë¥  DBì™€ ë‰´ìŠ¤ DB ëª¨ë‘ KoSBERT 768ì°¨ì› ì„ë² ë”© ì‚¬ìš©")
        
        # ì„ê³„ê°’ ì„¤ì •
        self.legal_similarity_threshold = 0.7
        self.news_similarity_threshold = 0.6
        self.min_relevant_docs = 3
        
        # DB ì—°ê²° ìµœì í™”
        self._init_legal_db(legal_db_path, legal_collection)
        self._init_news_db(news_db_path, news_collection)
        
        init_time = time.time() - start_time
        print(f"âš¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.2f}ì´ˆ)")
    
    def _init_legal_db(self, legal_db_path, legal_collection):
        """ë²•ë¥  DB ì´ˆê¸°í™” ìµœì í™”"""
        print(f"ğŸ›ï¸ ë²•ë¥  DB ì—°ê²° ì¤‘...")
        try:
            self.legal_db = Chroma(
                persist_directory=legal_db_path,
                collection_name=legal_collection,
                embedding_function=self.legal_embedding_function
            )
            
            self.legal_documents = None
            self.legal_bm25_retriever = None
            self.legal_hybrid_retriever = None
            
            self.legal_vector_retriever = self.legal_db.as_retriever(
                search_type="similarity", 
                search_kwargs={"k": 5}
            )
            print("âœ… ë²•ë¥  DB ì—°ê²° ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë²•ë¥  DB ì—°ê²° ì‹¤íŒ¨: {e}")
            self.legal_db = None
            self.legal_vector_retriever = None
    
    def _init_news_db(self, news_db_path, news_collection):
        """ë‰´ìŠ¤ DB ì´ˆê¸°í™” ìµœì í™”"""
        print(f"ğŸ“° ë‰´ìŠ¤ DB ì—°ê²° ì¤‘...")
        try:
            self.news_db = Chroma(
                persist_directory=news_db_path,
                collection_name=news_collection,
                embedding_function=self.legal_embedding_function
            )
            
            news_count = self.news_db._collection.count()
            print(f"âœ… ë‰´ìŠ¤ DB ì—°ê²° ì™„ë£Œ (ë¬¸ì„œ ìˆ˜: {news_count})")
            
            try:
                test_docs = self.news_db.similarity_search("ì „ì„¸", k=1)
                print(f"ğŸ§ª ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(test_docs)}ê°œ")
                if test_docs:
                    print(f"   ìƒ˜í”Œ ì œëª©: {test_docs[0].metadata.get('title', 'ì œëª©ì—†ìŒ')[:50]}...")
            except Exception as test_e:
                print(f"âš ï¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_e}")
            
            self.news_vector_retriever = self.news_db.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 4}
            )
            
            print("âœ… ë‰´ìŠ¤ DB KoSBERT 768ì°¨ì› ì„ë² ë”© ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ DB ì—°ê²° ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            self.news_db = None
            self.news_vector_retriever = None
    
    def _lazy_init_hybrid_retriever(self):
        """í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì§€ì—° ì´ˆê¸°í™”"""
        if self.legal_hybrid_retriever is None and self.legal_db is not None:
            print("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì¤‘...")
            try:
                legal_data = self.legal_db.get()
                
                if not legal_data or not legal_data.get("documents"):
                    print("âš ï¸ ë²•ë¥  DBì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
                    return
                
                all_legal_docs = legal_data["documents"]
                all_legal_metadatas = legal_data.get("metadatas", [{}] * len(all_legal_docs))
                
                if len(all_legal_metadatas) < len(all_legal_docs):
                    all_legal_metadatas.extend([{}] * (len(all_legal_docs) - len(all_legal_metadatas)))
                
                self.legal_documents = [
                    Document(page_content=doc, metadata=meta or {})
                    for doc, meta in zip(all_legal_docs, all_legal_metadatas)
                ]
                
                print(f"ğŸ“„ ë²•ë¥  ë¬¸ì„œ ë¡œë”© ì™„ë£Œ: {len(self.legal_documents)}ê°œ")
                
                self.legal_bm25_retriever = BM25Retriever.from_documents(self.legal_documents)
                self.legal_bm25_retriever.k = 8
                
                self.legal_hybrid_retriever = EnsembleRetriever(
                    retrievers=[self.legal_vector_retriever, self.legal_bm25_retriever],
                    weights=[0.65, 0.35]
                )
                print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì™„ë£Œ")
                
            except Exception as e:
                print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨, ë²¡í„° ê²€ìƒ‰ë§Œ ì‚¬ìš©: {e}")
                import traceback
                print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
                self.legal_hybrid_retriever = None
    
    def calculate_cosine_similarity_score(self, query, docs, use_news_embedding=False):
        """ìµœì í™”ëœ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not docs:
            return 0.0
        
        try:
            query_embedding = self.legal_embedding_function.embed_query(query)
            
            if not isinstance(query_embedding, np.ndarray):
                query_embedding = np.array(query_embedding)
            
            if query_embedding.ndim > 1:
                query_embedding = query_embedding.flatten()
            
            limited_docs = docs[:5]
            doc_texts = [doc.page_content[:1500] for doc in limited_docs]
            
            doc_embeddings = self.legal_embedding_function.embed_documents(doc_texts)
            
            if not isinstance(doc_embeddings, np.ndarray):
                doc_embeddings = np.array(doc_embeddings)
            
            if doc_embeddings.ndim == 1:
                doc_embeddings = doc_embeddings.reshape(1, -1)
            
            if query_embedding.shape[0] != doc_embeddings.shape[1]:
                print(f"âš ï¸ ì°¨ì› ë¶ˆì¼ì¹˜: ì¿¼ë¦¬ {query_embedding.shape[0]}, ë¬¸ì„œ {doc_embeddings.shape[1]}")
                return 0.65
            
            similarities = cosine_similarity([query_embedding], doc_embeddings)[0]
            
            return float(np.max(similarities)) if len(similarities) > 0 else 0.0
            
        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.65
    
    def search_legal_db(self, query):
        """ìµœì í™”ëœ ë²•ë¥  DB ê²€ìƒ‰"""
        if self.legal_db is None:
            print("âŒ ë²•ë¥  DBê°€ ì—°ê²°ë˜ì§€ ì•ŠìŒ")
            return [], 0.0
        
        try:
            # ğŸ” ì¿¼ë¦¬ í™•ì¥ ì ìš©
            expanded_query = self._expand_query_with_legal_terms(query)
            if expanded_query != query:
                print(f"ğŸ”„ í™•ì¥ëœ ë²•ë¥  ê²€ìƒ‰ ì¿¼ë¦¬: {expanded_query}")
            else:
                print(f"ğŸ” ë²•ë¥  DB ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
            
            # í™•ì¥ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
            legal_docs = self.legal_vector_retriever.invoke(expanded_query)
            print(f"ğŸ“„ ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(legal_docs)}ê°œ ë¬¸ì„œ")
            
            if legal_docs:
                for i, doc in enumerate(legal_docs[:2]):
                    doc_type = doc.metadata.get('doc_type', 'ìœ í˜•ë¶ˆëª…')
                    content_preview = str(doc.page_content)[:50] if doc.page_content else "ë‚´ìš©ì—†ìŒ"
                    print(f"   [{i+1}] {doc_type}: {content_preview}...")
            else:
                print("   âš ï¸ ë²¡í„° ê²€ìƒ‰ì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨")
            
            if len(legal_docs) < self.min_relevant_docs:
                print(f"ğŸ“Š ë¬¸ì„œ ê°œìˆ˜ ë¶€ì¡±({len(legal_docs)} < {self.min_relevant_docs}), í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œë„")
                self._lazy_init_hybrid_retriever()
                if self.legal_hybrid_retriever is not None:
                    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ë„ í™•ì¥ëœ ì¿¼ë¦¬ ì‚¬ìš©
                    hybrid_docs = self.legal_hybrid_retriever.invoke(expanded_query)
                    print(f"ğŸ“„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼: {len(hybrid_docs)}ê°œ ë¬¸ì„œ")
                    if len(hybrid_docs) > len(legal_docs):
                        legal_docs = hybrid_docs
                        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ë¡œ êµì²´")
            
            if len(legal_docs) > 5:
                legal_docs = LongContextReorder().transform_documents(legal_docs)
                print("ğŸ”„ ë¬¸ì„œ ì¬ì •ë ¬ ì™„ë£Œ")
            
            # ìœ ì‚¬ë„ ê³„ì‚°ì€ ì›ë³¸ ì¿¼ë¦¬ë¡œ (ë” ì •í™•í•œ í‰ê°€ë¥¼ ìœ„í•´)
            similarity_score = self.calculate_cosine_similarity_score(query, legal_docs, use_news_embedding=False)
            print(f"ğŸ“Š ë²•ë¥  DB ìµœì¢… ì ìˆ˜: {similarity_score:.3f}")
            
            return legal_docs, similarity_score
            
        except Exception as e:
            print(f"âŒ ë²•ë¥  DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return [], 0.0
    
    def search_news_db(self, query):
        """ìµœì í™”ëœ ë‰´ìŠ¤ DB ê²€ìƒ‰"""
        if self.news_db is None or self.news_vector_retriever is None:
            print("âŒ ë‰´ìŠ¤ DBê°€ ì—°ê²°ë˜ì§€ ì•ŠìŒ")
            return [], 0.0
        
        try:
            enhanced_query = self._enhance_news_query(query)
            print(f"ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬: {enhanced_query}")
            
            news_docs = self.news_vector_retriever.invoke(enhanced_query)
            print(f"ğŸ“° ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼: {len(news_docs)}ê°œ")
            
            if news_docs:
                for i, doc in enumerate(news_docs[:2]):
                    title = doc.metadata.get('title', 'ì œëª©ì—†ìŒ')
                    print(f"   [{i+1}] {title[:50]}...")
            else:
                print("   âš ï¸ ë‰´ìŠ¤ ê²€ìƒ‰ì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í•¨")
            
            if news_docs:
                similarity_score = self.calculate_cosine_similarity_score(
                    enhanced_query, news_docs, use_news_embedding=False
                )
                print(f"ğŸ“Š ë‰´ìŠ¤ ê²€ìƒ‰ ì ìˆ˜: {similarity_score:.3f}")
            else:
                similarity_score = 0.0
            
            return news_docs, similarity_score
            
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ DB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return [], 0.0
    
    def _expand_query_with_legal_terms(self, query):
        """ë²•ë¥  ì¿¼ë¦¬ í™•ì¥ - ë™ì˜ì–´ì™€ ê´€ë ¨ ìš©ì–´ ì¶”ê°€"""
        expansion_terms = []
        
        # ë¶€ë™ì‚° ê´€ë ¨ í™•ì¥
        if "ë³´ì¦ê¸ˆ" in query: 
            expansion_terms.extend(["ì„ëŒ€ì°¨ë³´ì¦ê¸ˆ", "ì „ì„¸ê¸ˆ"])
        if "ì§‘ì£¼ì¸" in query: 
            expansion_terms.append("ì„ëŒ€ì¸")
        if "ì„¸ì…ì" in query: 
            expansion_terms.append("ì„ì°¨ì¸")
        if "ì›”ì„¸" in query:
            expansion_terms.append("ì°¨ì„")
        if "ê³„ì•½ì„œ" in query:
            expansion_terms.append("ì„ëŒ€ì°¨ê³„ì•½ì„œ")
        
        # ë²•ì  ì ˆì°¨ ê´€ë ¨ í™•ì¥
        if "ì†Œì†¡" in query:
            expansion_terms.extend(["ë¯¼ì‚¬ì†Œì†¡", "ì†Œì†¡ì ˆì°¨"])
        if "ì†í•´ë°°ìƒ" in query:
            expansion_terms.append("ë°°ìƒì²­êµ¬")
        if "ëª…ë„" in query:
            expansion_terms.extend(["ëª…ë„ì²­êµ¬", "í‡´ê±°"])
        
        # ì „ì„¸ì‚¬ê¸° ê´€ë ¨ í™•ì¥
        if any(term in query for term in ["ì‚¬ê¸°", "ê¹¡í†µì „ì„¸", "ì „ì„¸ì‚¬ê¸°"]):
            expansion_terms.extend(["ì „ì„¸ì‚¬ê¸°", "ì„ëŒ€ì°¨ì‚¬ê¸°", "ë³´ì¦ê¸ˆì‚¬ê¸°"])
        
        # ìµœëŒ€ 3ê°œ ìš©ì–´ë§Œ ì¶”ê°€ (ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ)
        if expansion_terms:
            unique_terms = list(set(expansion_terms))[:3]
            expanded_query = f"{query} {' '.join(unique_terms)}"
            return expanded_query
        
        return query
    
    def _enhance_news_query(self, query):
        """ë‰´ìŠ¤ ì¿¼ë¦¬ ê°•í™”"""
        # ê¸°ë³¸ ê°•í™”
        enhanced = query
        if any(term in query for term in ["ì „ì„¸", "ë¶€ë™ì‚°", "ì„ëŒ€", "ì‚¬ê¸°"]):
            enhanced = f"{query} ì „ì„¸ì‚¬ê¸°"
        
        return enhanced
    
    def conditional_retrieve(self, original_query):
        """ì¡°ê±´ë¶€ ê²€ìƒ‰ - ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì¶”ê°€"""
        try:
            print(f"ğŸ” ì›ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬: {original_query}")
            
            # âœ… í•µì‹¬ ì¶”ê°€: ì¼ìƒì–´ â†’ ë²•ë¥ ì–´ ì „ì²˜ë¦¬
            converted_query, conversion_method = self.query_preprocessor.convert_query(original_query)
            
            if conversion_method != "no_conversion":
                print(f"ğŸ”„ ë³€í™˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬: {converted_query}")
                print(f"ğŸ“‹ ë³€í™˜ ë°©ë²•: {conversion_method}")
                # ì‹¤ì œ ê²€ìƒ‰ì—ëŠ” ë³€í™˜ëœ ì¿¼ë¦¬ ì‚¬ìš©
                search_query = converted_query
            else:
                print("ğŸ“‹ ì´ë¯¸ ë²•ë¥  ìš©ì–´ë¡œ êµ¬ì„±ëœ ì¿¼ë¦¬")
                search_query = original_query
            
            # 1ë‹¨ê³„: ë²•ë¥  DB ê²€ìƒ‰ (ë³€í™˜ëœ ì¿¼ë¦¬ ì‚¬ìš©)
            print("ğŸ›ï¸ ë²•ë¥  DB ê²€ìƒ‰ ì¤‘...")
            legal_docs, legal_score = self.search_legal_db(search_query)
            print(f"ğŸ“Š ë²•ë¥  DB ê²°ê³¼: {len(legal_docs)}ê°œ ë¬¸ì„œ, ì ìˆ˜: {legal_score:.3f}")
            
            # 2ë‹¨ê³„: ë²•ë¥  DB ê²°ê³¼ ì¶©ë¶„ì„± í‰ê°€
            is_legal_sufficient = (
                legal_score >= self.legal_similarity_threshold and 
                len(legal_docs) >= self.min_relevant_docs
            )
            
            if is_legal_sufficient:
                print("âœ… ë²•ë¥  DB ê²°ê³¼ë§Œìœ¼ë¡œ ì¶©ë¶„í•¨")
                return legal_docs, "legal_only"
            
            # 3ë‹¨ê³„: ë²•ë¥  DB ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°ì—ë§Œ ë‰´ìŠ¤ DB ê²€ìƒ‰
            print("ğŸ“° ë²•ë¥  DB ê²°ê³¼ ë¶€ì¡±, ë‰´ìŠ¤ DBë¡œ ë³´ì™„ ê²€ìƒ‰...")
            news_docs, news_score = self.search_news_db(search_query)
            print(f"ğŸ“Š ë‰´ìŠ¤ DB ê²°ê³¼: {len(news_docs)}ê°œ ë¬¸ì„œ, ì ìˆ˜: {news_score:.3f}")
            
            # 4ë‹¨ê³„: ê²°ê³¼ ê²°í•©
            combined_docs = []
            
            if legal_docs:
                combined_docs.extend(legal_docs[:8])  # ë²•ë¥  ë¬¸ì„œ ìµœëŒ€ 8ê°œë¡œ ì¦ê°€
                print(f"âœ… ë²•ë¥  ë¬¸ì„œ {len(legal_docs[:8])}ê°œ ì¶”ê°€")
            
            if news_docs and news_score >= self.news_similarity_threshold:
                combined_docs.extend(news_docs[:3])  # ë‰´ìŠ¤ëŠ” 3ê°œë¡œ ì¡°ì • (ì´ 11ê°œ ë°©ì§€)
                print(f"âœ… ë‰´ìŠ¤ ë¬¸ì„œ {len(news_docs[:5])}ê°œ ì¶”ê°€")
                search_type = "legal_and_news"
            elif legal_docs:
                search_type = "legal_only"
            else:
                search_type = "no_results"
            
            print(f"ğŸ¯ ìµœì¢… ê²°ê³¼: {len(combined_docs)}ê°œ ë¬¸ì„œ ({search_type})")
            return combined_docs, search_type
                
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return [], "error"

# 4. ìµœì í™”ëœ ë¬¸ì„œ í¬ë§·íŒ… (ê¸°ì¡´ê³¼ ë™ì¼)
def format_docs_optimized(docs, search_type):
    """ìµœì í™”ëœ ë¬¸ì„œ í¬ë§·íŒ… - ì¶œì²˜ë³„ ëª…í™•í•œ êµ¬ë¶„"""
    if not docs:
        return "ê´€ë ¨ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_docs = []
    news_count = 0
    precedent_count = 0
    interpretation_count = 0
    qa_count = 0
    
    for i, doc in enumerate(docs):
        try:
            meta = doc.metadata if doc.metadata else {}
            content = str(doc.page_content)[:1000] if doc.page_content else ""
            
            is_news = ('url' in meta and 'title' in meta) or ('date' in meta and 'title' in meta)
            
            if is_news:
                news_count += 1
                title = str(meta.get("title", "ì œëª©ì—†ìŒ"))[:80]
                date = str(meta.get("date", "ë‚ ì§œë¯¸ìƒ"))
                source = str(meta.get("source", "ë‰´ìŠ¤"))
                
                formatted = f"[ë‰´ìŠ¤-{news_count}] ğŸ“° ë‰´ìŠ¤\n"
                formatted += f"ì œëª©: {title}\n"
                formatted += f"ì¶œì²˜: {source} | ë‚ ì§œ: {date}\n"
                formatted += f"ë‚´ìš©: {content}...\n"
                
            else:
                doc_type = str(meta.get("doc_type", "")).lower()
                
                if any(keyword in doc_type for keyword in ["íŒë¡€", "íŒê²°", "ëŒ€ë²•ì›", "ê³ ë“±ë²•ì›", "ì§€ë°©ë²•ì›"]) or \
                   any(key in meta for key in ["íŒê²°ìš”ì§€", "íŒì‹œì‚¬í•­", "case_id", "court"]):
                    
                    case_id = str(meta.get("case_id", ""))
                    if case_id and case_id.strip() != "":
                        formatted = f"[íŒë¡€-{case_id}] ğŸ›ï¸ íŒë¡€\n"
                    else:
                        precedent_count += 1
                        formatted = f"[íŒë¡€-{precedent_count}] ğŸ›ï¸ íŒë¡€\n"
                    
                    formatted += f"ë‚´ìš©: {content}...\n"
                    
                elif any(keyword in doc_type for keyword in ["ë²•ë ¹í•´ì„", "í•´ì„ë¡€", "ìœ ê¶Œí•´ì„", "í–‰ì •í•´ì„"]) or \
                     any(key in meta for key in ["í•´ì„ë‚´ìš©", "ë²•ë ¹ëª…", "interpretation_id"]):
                    
                    interpretation_id = str(meta.get("interpretation_id", ""))
                    if interpretation_id and interpretation_id.strip() != "":
                        formatted = f"[ë²•ë ¹í•´ì„ë¡€-{interpretation_id}] âš–ï¸ ë²•ë ¹í•´ì„ë¡€\n"
                    else:
                        interpretation_count += 1
                        formatted = f"[ë²•ë ¹í•´ì„ë¡€-{interpretation_count}] âš–ï¸ ë²•ë ¹í•´ì„ë¡€\n"
                    
                    formatted += f"ë‚´ìš©: {content}...\n"
                    
                elif any(keyword in doc_type for keyword in ["ë°±ë¬¸ë°±ë‹µ", "ìƒí™œë²•ë ¹", "qa", "ì§ˆì˜ì‘ë‹µ", "faq"]) or \
                     any(key in meta for key in ["ì§ˆë¬¸", "ë‹µë³€", "question", "answer", "qa_id"]):
                    
                    qa_id = str(meta.get("qa_id", ""))
                    if qa_id and qa_id.strip() != "":
                        formatted = f"[ë°±ë¬¸ë°±ë‹µ-{qa_id}] ğŸ’¡ ìƒí™œë²•ë ¹ Q&A\n"
                    else:
                        qa_count += 1
                        formatted = f"[ë°±ë¬¸ë°±ë‹µ-{qa_count}] ğŸ’¡ ìƒí™œë²•ë ¹ Q&A\n"
                    
                    formatted += f"ë‚´ìš©: {content}...\n"
                    
                else:
                    precedent_count += 1
                    source = str(meta.get("doc_type", "ë²•ë¥ ìë£Œ"))
                    formatted = f"[ë²•ë¥ -{precedent_count}] ğŸ“‹ {source}\n"
                    formatted += f"ë‚´ìš©: {content}...\n"
            
            formatted_docs.append(formatted)
            
        except Exception as e:
            print(f"âš ï¸ ë¬¸ì„œ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
            try:
                content = str(doc.page_content)[:1000] if doc.page_content else "ë‚´ìš© ì—†ìŒ"
                formatted_docs.append(f"[ë¬¸ì„œ-{i+1}] {content}...")
            except:
                continue
    
    # ê²°ê³¼ ì¡°í•© - ìœ í˜•ë³„ ê°œìˆ˜ í‘œì‹œ
    header_parts = []
    if precedent_count > 0:
        header_parts.append(f"íŒë¡€ {precedent_count}ê°œ")
    if interpretation_count > 0:
        header_parts.append(f"ë²•ë ¹í•´ì„ë¡€ {interpretation_count}ê°œ")
    if qa_count > 0:
        header_parts.append(f"ìƒí™œë²•ë ¹Q&A {qa_count}ê°œ")
    if news_count > 0:
        header_parts.append(f"ë‰´ìŠ¤ {news_count}ê°œ")
    
    header = f"ğŸ“‹ ê²€ìƒ‰ê²°ê³¼: {', '.join(header_parts)}\n"
    header += "="*60 + "\n"
    header += "âš ï¸ AIê°€ ì•„ë˜ ìë£Œ ìœ í˜•ì„ ì •í™•íˆ í™•ì¸í•˜ê³  ë‹µë³€í•˜ì„¸ìš”:\n"
    
    if precedent_count > 0:
        header += f"â€¢ íŒë¡€ ìë£Œ: [íŒë¡€-ë²ˆí˜¸] ğŸ›ï¸ íŒë¡€ í˜•íƒœë¡œ í‘œì‹œë¨\n"
    if interpretation_count > 0:
        header += f"â€¢ ë²•ë ¹í•´ì„ë¡€ ìë£Œ: [ë²•ë ¹í•´ì„ë¡€-ë²ˆí˜¸] âš–ï¸ ë²•ë ¹í•´ì„ë¡€ í˜•íƒœë¡œ í‘œì‹œë¨\n"
    if qa_count > 0:
        header += f"â€¢ ìƒí™œë²•ë ¹ ìë£Œ: [ë°±ë¬¸ë°±ë‹µ-ë²ˆí˜¸] ğŸ’¡ ìƒí™œë²•ë ¹ Q&A í˜•íƒœë¡œ í‘œì‹œë¨\n"
    if news_count > 0:
        header += f"â€¢ ë‰´ìŠ¤ ìë£Œ: [ë‰´ìŠ¤-ë²ˆí˜¸] ğŸ“° ë‰´ìŠ¤ í˜•íƒœë¡œ í‘œì‹œë¨\n"
    
    header += "="*60 + "\n\n"
    
    result = header + "\n\n".join(formatted_docs)
    
    return result

# 5. í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
load_dotenv()
CHROMA_DB_PATH = "D:\\chroma_db_law_real_final"
NEWS_DB_PATH = "D:\\ja_chroma_db"
LEGAL_COLLECTION_NAME = "legal_db"
NEWS_COLLECTION_NAME = "jeonse_fraud_embedding"

# 6. ì „ì—­ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ (ì§€ì—° ì´ˆê¸°í™”)
_conditional_rag = None

def get_rag_system():
    """RAG ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _conditional_rag
    if _conditional_rag is None:
        _conditional_rag = OptimizedConditionalRAGSystem(
            legal_db_path=CHROMA_DB_PATH,
            news_db_path=NEWS_DB_PATH,
            legal_collection=LEGAL_COLLECTION_NAME,
            news_collection=NEWS_COLLECTION_NAME
        )
    return _conditional_rag

# 7. ìµœì í™”ëœ ê²€ìƒ‰ í•¨ìˆ˜
def optimized_retrieve_and_format(query):
    """ìµœì í™”ëœ ê²€ìƒ‰ ë° í¬ë§·íŒ… - ì „ì²˜ë¦¬ í¬í•¨"""
    try:
        rag_system = get_rag_system()
        docs, search_type = rag_system.conditional_retrieve(query)
        
        if not isinstance(docs, list):
            return f"ê²€ìƒ‰ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜: {type(docs)}"
        
        return format_docs_optimized(docs, search_type)
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# 8. ì¼ë°˜ ì‚¬ìš©ììš© ì²´ì¸ ìƒì„± - ì „ì²˜ë¦¬ ì •ë³´ í¬í•¨
def create_user_friendly_chat_chain():
    """ì¼ë°˜ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì¹œí™”ì  ì²´ì¸ - ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì •ë³´ í¬í•¨"""
    llm = ChatOpenAI(
        model="gpt-4o",
        temperature=0.3,
        max_tokens=3000,
    )
    

    system_message = """
    ë‹¹ì‹ ì€ ë¶€ë™ì‚° ì„ëŒ€ì°¨, ì „ì„¸ì‚¬ê¸°, ë²•ë ¹í•´ì„, ìƒí™œë²•ë ¹ Q&A, ë‰´ìŠ¤ ê¸°ì‚¬ ë“± ë‹¤ì–‘í•œ ë²•ë¥  ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²­ë…„ì„ ë•ëŠ” ë²•ë¥  ì „ë¬¸ê°€ AI ì±—ë´‡ì…ë‹ˆë‹¤.  
    íŠ¹íˆ ì „ì„¸ì‚¬ê¸° í”¼í•´ ë“± ë¶€ë™ì‚° ë¬¸ì œë¡œ ì–´ë ¤ì›€ì„ ê²ªëŠ” ì‚¬ëŒë“¤ì—ê²Œ ì‰½ê³  ì‹¤ì§ˆì ì¸ ë„ì›€ì„ ì œê³µí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

    ---

    ### âœ… ë‹µë³€ ì›ì¹™
    1. **ì–´ë ¤ìš´ ë²•ë¥  ìš©ì–´ëŠ” ì¼ìƒì ì¸ í‘œí˜„**ìœ¼ë¡œ ë°”ê¿” ì„¤ëª…í•©ë‹ˆë‹¤.  
    2. **êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ í•´ê²° ë°©ë²•**ì„ ì œì‹œí•©ë‹ˆë‹¤.  
    3. **ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ë§íˆ¬**ë¥¼ ì‚¬ìš©í•˜ì—¬, ë¶ˆì•ˆí•œ ìƒí™©ì— ìˆëŠ” ì‚¬ëŒì—ê²Œ ìœ„ë¡œì™€ í˜ì´ ë˜ë„ë¡ í•©ë‹ˆë‹¤.  
    4. **ë²•ë¥ ì  ê·¼ê±°ê°€ ìˆëŠ” ì •ë³´ë§Œ ì œê³µ**í•˜ë©°, ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œê¸°í•©ë‹ˆë‹¤.  

    ---

    ### ğŸ§­ ë‹µë³€ êµ¬ì¡°

    [ì§ˆë¬¸ í•´ì„ ì•ˆë‚´]  
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë²•ë¥  ê²€ìƒ‰ì— ì í•©í•˜ê²Œ ë°”ê¿”ì„œ ì´í•´í–ˆìŒì„ ê°„ë‹¨íˆ ì„¤ëª…í•©ë‹ˆë‹¤.<br>
    (ì˜ˆ: "ì§ˆë¬¸í•˜ì‹  ë‚´ìš©ì„ ë²•ë¥  ìš©ì–´ë¡œ ë°”ê¾¸ë©´ 'ë³´ì¦ê¸ˆì„ ëŒë ¤ë°›ì§€ ëª»í•œ ê²½ìš°ì— ëŒ€í•œ ë²•ì  ëŒ€ì‘'ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆì–´ìš”.")<br>

    ##### ğŸ”¹ **ìœ ì‚¬ íŒë¡€ ìš”ì•½**  
    ë²•ë¥  ë²¡í„°DBì—ì„œ ì°¾ì€ ê´€ë ¨ íŒë¡€ë¥¼ ì„¤ëª…í•˜ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ í•µì‹¬ ë‚´ìš©ì„ í’€ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.  
    ìœ ì‚¬ íŒë¡€ëŠ” 2ê°œë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”. 
    ì¶œì²˜ í‘œê¸°ëŠ” íŒë¡€ ìš”ì•½ ì•ì—ëŠ” ë‹¬ì§€ ë§ˆì„¸ìš”. ë‹µë³€ ë’¤ì— ë‹¬ì•„ì£¼ì„¸ìš”. 
    ê° íŒë¡€ ì•ì—ëŠ” 1, 2ë²ˆìœ¼ë¡œ ìˆ«ìë¥¼ ì ì–´ì£¼ì„¸ìš”. 
    â†’ ì¶œì²˜ í‘œê¸°: (ì˜ˆ: **[ì°¸ê³ : íŒë¡€-194950]**

    ##### ğŸ”¹ **ê´€ë ¨ ë‰´ìŠ¤**  
    ë‰´ìŠ¤ ë°±í„°DBì—ì„œ ì°¾ì€ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì„¤ëª…í•˜ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ í•µì‹¬ ë‚´ìš©ì„ í’€ì–´ ì„¤ëª…í•©ë‹ˆë‹¤.  
    ë‰´ìŠ¤ ë°±í„°DBì—ì„œ ì°¾ì€ ë‰´ìŠ¤ê°€ ì—†ë‹¤ë©´ **[ê´€ë ¨ ë‰´ìŠ¤]** ë¶€ë¶„ì€ ì „ì²´ ìƒëµí•˜ì„¸ìš”.  
    â†’ ì¶œì²˜ í‘œê¸°: **[ì°¸ê³ : ë‰´ìŠ¤]**

    ##### ğŸ”¹ **ë²•ë ¹í•´ì„ë¡€, ìƒí™œë²•ë ¹ Q&A ì°¸ê³ **  
    ë²•ë ¹í•´ì„ë¡€, ìƒí™œë²•ë ¹ Q&A ì— ìœ ì‚¬í•œ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš° ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ ì„¤ëª…í•˜ê³ ,  
    ì—†ë‹¤ë©´ **[ë²•ë ¹í•´ì„ë¡€, ìƒí™œë²•ë ¹ Q&A ì°¸ê³ ]** ë¶€ë¶„ì€ ì „ì²´ ìƒëµí•˜ì„¸ìš”.  

    ì •ë¶€ ê¸°ê´€ì˜ ìœ ê¶Œí•´ì„ì´ ìˆëŠ” ê²½ìš° ì„¤ëª…í•˜ê³ , ì‹¤ìƒí™œì— ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ë„ ì•ˆë‚´í•©ë‹ˆë‹¤.  
    â†’ ì¶œì²˜ í‘œê¸°: **[ì°¸ê³ : ë²•ë ¹í•´ì„ë¡€]**

    ìƒí™œë²•ë ¹ì •ë³´ 'ë°±ë¬¸ë°±ë‹µ' ì¤‘ ìœ ì‚¬ ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ ì„¤ëª…í•˜ë©° ì—°ê²°í•´ì¤ë‹ˆë‹¤.  
    â†’ ì¶œì²˜ í‘œê¸°: **[ì°¸ê³ : ìƒí™œë²•ë ¹]**

    ---

    ##### âœ”ï¸ **í–‰ë™ë°©ì¹¨ ì œì•ˆ**  
    ìœ„ì˜ ë²•ë¥  ìë£Œë“¤ì„ ì¢…í•©í•˜ì—¬ ì§€ê¸ˆ ìƒí™©ì—ì„œ í•  ìˆ˜ ìˆëŠ” **ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš** ì œì‹œ:
 

    ê° ë‹¨ê³„ë³„ë¡œ ë°©ë²•, ì—°ë½ì²˜, ë¹„ìš© ë“±ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.
    ë‹¨ê³„ ë‹¹ 1ì¤„ì„ ë„˜ì§€ ë§ˆì„¸ìš”.

    ###### â€» **ìœ ì˜ì‚¬í•­**  
    ë²•ë¥  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì£¼ì˜ì :  
    - íŒë¡€/í•´ì„ë¡€ì—ì„œ ë‚˜íƒ€ë‚œ ì£¼ì˜í•  ì ë“¤  
    - ì‹¤ìˆ˜í•˜ê¸° ì‰¬ìš´ ë¶€ë¶„ê³¼ ëŒ€ë¹„ì±…  
    - ì „ë¬¸ê°€ ìƒë‹´ì´ í•„ìš”í•œ ê²½ìš°ì™€ ìƒë‹´ ê¸°ê´€ ì•ˆë‚´  
    - ë²•ì  ë¶„ìŸì—ì„œ ì£¼ì˜í•´ì•¼ í•  ì ì´ë‚˜ ì¶”ê°€ë¡œ ê³ ë ¤í•  ì‚¬í•­ ì •ë¦¬  

    ìœ ì˜ì‚¬í•­ì€ í•µì‹¬ ë‚´ìš©ë§Œ 1ì¤„ë¡œ ìš”ì•½í•˜ì„¸ìš”.

    ---

    ### ğŸ“Œ ì¤‘ìš” ì§€ì¹¨
    - ê° ìë£Œì˜ **êµ¬ì²´ì ì¸ ë²ˆí˜¸ë‚˜ ì‹ë³„ì**ë¥¼ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”.  
    - ì°¸ê³ ìë£Œì˜ ë‚´ìš©ì„ **ë‹¨ìˆœ ë³µì‚¬í•˜ì§€ ë§ê³ **, ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ê²Œ **í•´ì„í•˜ì—¬ ì„¤ëª…**í•˜ì„¸ìš”.  
    - contextì— í•´ë‹¹ ìœ í˜•ì˜ ìë£Œê°€ ì—†ìœ¼ë©´ **ê·¸ ìë£ŒëŠ” ìƒëµ**í•˜ì„¸ìš”.  
    - í•„ìš” ì‹œ **ë²•ë¥  ìƒë‹´, ìƒë‹´ ê¸°ê´€ ë“±ë„ ì•ˆë‚´**í•©ë‹ˆë‹¤.  
    - **ì¤‘ë³µëœ ë‚´ìš©ì€ í•œ ë²ˆë§Œ** í‘œê¸°í•˜ì„¸ìš”.  
    â†’ ì¶œì²˜ í‘œê¸°: **[ì°¸ê³ : íŒë¡€]**
    """

    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}"),
        ("system", "ì°¸ê³ ìë£Œ:\n{context}")
    ])
    
    def user_friendly_retrieve_and_format(query):
        """ì‚¬ìš©ì ì¹œí™”ì  ê²€ìƒ‰ ë° í¬ë§·íŒ… - ì „ì²˜ë¦¬ í¬í•¨"""
        try:
            rag_system = get_rag_system()
            docs, search_type = rag_system.conditional_retrieve(query)
            formatted_result = format_docs_optimized(docs, search_type)
            return formatted_result
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    chain = (
        {
            "context": RunnableLambda(lambda x: user_friendly_retrieve_and_format(x["question"])),
            "question": RunnableLambda(lambda x: x["question"]),
            "chat_history": RunnableLambda(lambda x: x.get("chat_history", [])),
        }
        | prompt
        | llm
        | StrOutputParser()
    )
    return chain


# 9. ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”
store = {}

def get_session_history(session_id):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    history = store[session_id]
    if len(history.messages) > 20:
        history.messages = history.messages[-20:]
    return history

def create_chat_chain_with_memory():
    """ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì´ ìˆëŠ” ì‚¬ìš©ì ì¹œí™”ì  ì²´ì¸ ìƒì„±"""
    base_chain = create_user_friendly_chat_chain()
    chain_with_history = RunnableWithMessageHistory(
        base_chain,
        get_session_history,
        input_messages_key="question",
        history_messages_key="chat_history",
    )
    return chain_with_history



# â€”â€”â€” ê´‘ê³  ë°°ë„ˆ í•¨ìˆ˜ (ì´ë¯¸ì§€ í¬í•¨ëœ ë²„ì „) â€”â€”â€”

import streamlit as st

def display_ad_banner():
    st.markdown("---")
    st.markdown('<h5 style="color: #b45309;">âœ¨ ì¶”ì²œ ë¶€ë™ì‚° ì „ë¬¸ê°€</h5>', unsafe_allow_html=True)

    ads = [
        {
            "img": "https://search.pstatic.net/common/?autoRotate=true&type=w560_sharpen&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20180518_269%2F1526627900915a2haI_PNG%2FDhZnKmpdc0bNIHMpMyeDLuUE.png",
            "title": "ğŸ¢ ëŒ€ì¹˜ë˜ë¯¸ì•ˆê³µì¸ì¤‘ê°œì‚¬ì‚¬ë¬´ì†Œ",
            "phone": "0507-1408-0123",
            "desc": "ğŸ“ ì„œìš¸ ê°•ë‚¨êµ¬ ëŒ€ì¹˜ë™",
            "link": "https://naver.me/xslBVRJX"
        },
        {
            "img": "https://search.pstatic.net/common/?src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20250331_213%2F1743412607070OviNF_JPEG%2F1000049538.jpg",
            "title": "ğŸ¡ ë©”ì¢…ê³µì¸ì¤‘ê°œì‚¬ì‚¬ë¬´ì†Œ",
            "phone": "0507-1431-4203",
            "desc": "ğŸ  ì „ë¬¸ ë¶€ë™ì‚° ìƒë‹´",
            "link": "https://naver.me/IgJnnCcG"
        },
        {
            "img": "https://search.pstatic.net/common/?autoRotate=true&type=w560_sharpen&src=https%3A%2F%2Fldb-phinf.pstatic.net%2F20200427_155%2F15879809374237E6dq_PNG%2FALH-zx7fy26wJg1T6EUOHC0W.png",
            "title": "ğŸ‘‘ ë¡œì–„ê³µì¸ì¤‘ê°œì‚¬ì‚¬ë¬´ì†Œ",
            "phone": "02-569-8889",
            "desc": "ğŸŒŸ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê±°ë˜",
            "link": "https://naver.me/5GGPXQe8"
        }
    ]

    for ad in ads:
        st.markdown(f"""
        <div style="
            background-color: #fffbea;
            border-radius: 15px;
            padding: 15px;
            margin-bottom: 20px;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.06);
        ">
            <div style="display: flex; align-items: center;">
                <img src="{ad['img']}" style="width: 3cm; height: 2cm; object-fit: cover; border-radius: 8px; margin-right: 15px;" />
                <div>
                    <p style="margin-bottom: 5px; font-size: 16px; font-weight: 600;">{ad['title']}</p>
                    <p style="margin: 0;">â˜ <strong>{ad['phone']}</strong></p>
                    <p style="margin: 0;">{ad['desc']}</p>
                    <a href="{ad['link']}" target="_blank" style="color: #b45309; font-weight: bold;">ğŸ”— ë°”ë¡œê°€ê¸°</a>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")
    st.markdown("ğŸ’¡ **ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¶€ë™ì‚° ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”**")





# â€”â€”â€” Streamlit UI â€”â€”â€”
st.set_page_config(
    page_title="AI ìŠ¤ìœ„ì¹˜ì˜¨ - íŒë¡€ ê²€ìƒ‰ ì‹œìŠ¤í…œ", 
    page_icon="ğŸ ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS ë¡œë“œ
load_custom_css()

# â€”â€”â€” í—¤ë” â€”â€”â€”
st.markdown("""
<div class="header-container">
    <div class="header-title">ğŸ’¡ <span class="highlight">AI ìŠ¤ìœ„ì¹˜ì˜¨</span></div>
    <div class="header-subtitle">íŒë¡€ ê¸°ë°˜ AI ë¶€ë™ì‚° ê±°ë˜ ì§€ì› ì„œë¹„ìŠ¤</div>
    <div style="margin-top: 1rem; font-size: 1rem; color: #e5e7eb;">
        ğŸ’¡ ìƒí™©ì„ ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì‹œë©´ ë§ì¶¤í˜• ë²•ë¥  ì •ë³´ë¥¼ ì œê³µí•´ë“œë¦½ë‹ˆë‹¤
    </div>
</div>
""", unsafe_allow_html=True)

# â€”â€”â€” ì„¸ì…˜ ì´ˆê¸°í™” â€”â€”â€”
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

chain = create_chat_chain_with_memory()



# â€”â€”â€” ì‚¬ì´ë“œë°” â€”â€”â€”
with st.sidebar:
    st.markdown("""
    <div style="text-align: center; padding: 1rem;">
        <h2 style="color: #6b21a8; margin-bottom: 1rem;">ğŸ” ë¹ ë¥¸ ì§ˆë¬¸</h2>
    </div>
    """, unsafe_allow_html=True)
    
    example_questions = [
        "ì „ì„¸ì‚¬ê¸° ë‹¹í–ˆì„ ë•Œ ëŒ€ì²˜ë°©ë²•ì€?",
        "ë³´ì¦ê¸ˆì„ ëŒë ¤ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?",
        "ì„ì°¨ê¶Œë“±ê¸°ëª…ë ¹ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì§‘ì£¼ì¸ì´ ë“±ê¸°ì´ì „ì„ ì•ˆ í•´ì¤„ ë•Œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
        "ì§‘ì´ ê²½ë§¤ë¡œ ë„˜ì–´ê°”ì„ ë•Œ ì „ì„¸ë³´ì¦ê¸ˆì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
    ]
    
    for i, q in enumerate(example_questions):
        if st.button(f" {q}", key=f"example_{i}", use_container_width=True):
            st.session_state["sidebar_prompt"] = q
            st.rerun()

    st.markdown("<br>", unsafe_allow_html=True)
    
    if st.button("â†» ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True, type="secondary"):
        st.session_state.chat_history = []
        st.rerun()

    st.markdown("<hr>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class="sidebar-card" style="border: 2px solid #8b5cf6; padding: 1rem; border-radius: 0.5rem; box-shadow: 2px 2px 10px rgba(139, 92, 246, 0.2);">
        <h4 style="color: #6b21a8; margin-bottom: 1rem;">âœ”ï¸ ì„œë¹„ìŠ¤ ì•ˆë‚´</h4>
        <ul style="color: #4b5563; line-height: 1.6; font-weight: bold;">
            <li>ë¶€ë™ì‚° ê´€ë ¨ ë²•ë¥  ë¬¸ì œ ìƒë‹´</li>
            <li>íŒë¡€ ê¸°ë°˜ ë‹µë³€ ì œê³µ</li>
            <li>ì „ì„¸ì‚¬ê¸° í”¼í•´ ëŒ€ì²˜ë°©ì•ˆ ì•ˆë‚´</li>
            <li>ì¼ë°˜ì¸ë„ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)


    st.markdown("""
    <div class="sidebar-card" style="background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border: 2px solid #f5bd5f;">
        <h4 style="color: #80370b; margin-bottom: 1rem;">âš ï¸ ì£¼ì˜ì‚¬í•­</h4>
        <ul style="color: #92400e; line-height: 1.6; margin: 0;">
            <li>ë³¸ ì„œë¹„ìŠ¤ëŠ” ë¶€ë™ì‚° ë²•ë¥  ì •ë³´ë¥¼ ì°¸ê³ ìš©ìœ¼ë¡œ ì œê³µí•˜ëŠ” AIë¡œ, ë²•ë¥  ì „ë¬¸ê°€ê°€ ì•„ë‹™ë‹ˆë‹¤.</li>
            <li>ì¤‘ìš”í•œ ë²•ì  ë¬¸ì œëŠ” ë°˜ë“œì‹œ ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œë©°, ì±—ë´‡ì˜ ë‹µë³€ì— ëŒ€í•œ ë²•ì  ì±…ì„ì„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)


# â€”â€”â€” ì±„íŒ… UI â€”â€”â€”
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for message in st.session_state.chat_history:
    if message["role"] == "user":
        st.markdown(f"""
        <div class="user-message">
            <div class="user-bubble">
                {message["content"]}
            </div>
        </div>
        """, unsafe_allow_html=True)

    elif message["role"] == "assistant":
        st.markdown(f"""
        <div class="ai-message">
            <div class="ai-bubble">
                {message["content"]}
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # AI ë‹µë³€ í›„ ê´‘ê³  ë°°ë„ˆ í‘œì‹œ
        display_ad_banner()

st.markdown('</div>', unsafe_allow_html=True)

# â€”â€”â€” ì§ˆë¬¸ ì…ë ¥ â€”â€”â€”
prompt = st.session_state.pop("sidebar_prompt", None)
if not prompt:
    # ì»¤ìŠ¤í…€ ì…ë ¥ì°½ ìŠ¤íƒ€ì¼
    st.markdown("""
    <div style="position: sticky; bottom: 0; background: rgba(255,255,255,0.95); 
                padding: 1rem; border-radius: 15px; margin-top: 2rem;
                box-shadow: 0 -5px 15px rgba(139, 92, 246, 0.1);
                backdrop-filter: blur(10px);">
    """, unsafe_allow_html=True)
    
    prompt = st.chat_input("ğŸ’­ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë³´ì¦ê¸ˆ ëŒë ¤ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?)", key="user_input")
    
    st.markdown("</div>", unsafe_allow_html=True)


if prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
    st.session_state.chat_history.append({"role": "user", "content": prompt})

    # ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ê³¼ í•¨ê»˜ ë‹µë³€ ìƒì„±
    with st.spinner("ğŸ¤– AIê°€ íŒë¡€ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            response = chain.invoke(
                {"question": prompt},
                config={"configurable": {"session_id": st.session_state.session_id}},
            )
            st.session_state.chat_history.append({"role": "assistant", "content": response})
        except Exception as e:
            error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            st.session_state.chat_history.append({"role": "assistant", "content": error_message})

    # ë‹µë³€ ìƒì„± í›„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
    st.rerun()

# â€”â€”â€” í‘¸í„° â€”â€”â€”
st.markdown("""
<div style="margin-top: 3rem; padding: 2rem; text-align: center; 
           background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
           border-radius: 15px; border-top: 3px solid #8b5cf6;">
    <p style="color: #6b7280; margin: 0;">
        ğŸ’¡ <strong>AI ìŠ¤ìœ„ì¹˜ì˜¨</strong> | ë¶€ë™ì‚° ë²•ë¥  ìƒë‹´ AI ì„œë¹„ìŠ¤<br>
        <span style="font-size: 0.9rem;">â€» ë³¸ ì„œë¹„ìŠ¤ëŠ” ì°¸ê³ ìš©ì´ë©°, ì‹¤ì œ ë²•ë¥  ë¬¸ì œëŠ” ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.</span>
    </p>
</div>
""", unsafe_allow_html=True)
